
# %% [code] {"scrolled":false}
def run_lgbm(train, cat_features=categorical, num_rounds=20000, folds=3):
    kf = GroupKFold(n_splits=folds)
    models = []
    #     param = {"objective": "regression",
    #              "boosting": "gbdt",
    #              "num_leaves": 1280,
    #              "learning_rate": 0.05,
    #              "feature_fraction": 0.85,
    #              "reg_lambda": 2,
    #              "metric": "rmse"
    #             }

    param = {'num_leaves': 500,
             'objective': 'regression',
             'learning_rate': 0.05,
             'boosting': 'gbdt',
             'subsample': 0.4,
             'feature_fraction': 0.7,
             'n_jobs': -1,
             'seed': 50,
             'metric': 'rmse'
             }
    oof = np.zeros(len(train))
    for tr_idx, val_idx in tqdm(kf.split(train, groups=train['group']), total=folds):
        tr_x, tr_y = train[features].iloc[tr_idx], train[target].iloc[tr_idx]
        vl_x, vl_y = train[features].iloc[val_idx], train[target].iloc[val_idx]
        tr_data = lgb.Dataset(tr_x, label=tr_y, categorical_feature=categorical)
        vl_data = lgb.Dataset(vl_x, label=vl_y, categorical_feature=categorical)
        clf = lgb.train(param, tr_data, num_rounds, valid_sets=[tr_data, vl_data], verbose_eval=25,
                        early_stopping_rounds=50)
        models.append(clf)
        oof[val_idx] = clf.predict(vl_x)
        gc.collect()
    score = np.sqrt(metrics.mean_squared_error(train[target], np.clip(oof, a_min=0, a_max=None)))
    print('Our oof cv is :', score)
    return models


models = run_lgbm(train_df)

# %% [code]
# read test
test_df = pd.read_csv('kaggle/input/test.csv')
row_ids = test_df["row_id"]
test_df.drop("row_id", axis=1, inplace=True)
test_df = reduce_mem_usage(test_df)

# merge with building info
test_df = test_df.merge(building_df, left_on='building_id', right_on='building_id', how='left')
del building_df
gc.collect()

# fill test weather data
weather_df = pd.read_csv('kaggle/input/weather_test.csv')
weather_df = fill_weather_dataset(weather_df)
weather_df = reduce_mem_usage(weather_df)

# merge weather data
test_df = test_df.merge(weather_df, how='left', on=['timestamp', 'site_id'])
del weather_df
gc.collect()

# feature engineering
test_df = features_engineering(test_df)


# %% [code]
def predictions(models, iterations=50):
    # split test data into batches
    set_size = len(test_df)
    batch_size = set_size // iterations
    meter_reading = []
    for i in tqdm(range(iterations)):
        pos = i * batch_size
        tfid = TfidfVectorizer()
        fold_preds = [np.expm1(model.predict(test_df[features].iloc[pos: pos + batch_size])) for model in models]
        meter_reading.extend(np.mean(fold_preds, axis=0))

    print(len(meter_reading))
    assert len(meter_reading) == set_size
    submission = pd.read_csv('kaggle/input/sample_submission.csv')
    submission['meter_reading'] = np.clip(meter_reading, a_min=0, a_max=None)  # clip min at zero
    submission.to_csv('submission.csv', index=False)
    print('We are done!')


predictions(models)
